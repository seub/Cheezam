{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Image classification: French cheeses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:12.934664Z",
     "iopub.status.busy": "2021-10-26T01:28:12.934088Z",
     "iopub.status.idle": "2021-10-26T01:28:14.628166Z",
     "shell.execute_reply": "2021-10-26T01:28:14.627600Z"
    },
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import os\n",
    "import pathlib\n",
    "import pickle\n",
    "# import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "In this notebook we use the dataset ```auto_dataset_cleaned```, which uses a script to automatically download images from the internet, that are then checked manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:14.633641Z",
     "iopub.status.busy": "2021-10-26T01:28:14.632652Z",
     "iopub.status.idle": "2021-10-26T01:28:26.151609Z",
     "shell.execute_reply": "2021-10-26T01:28:26.152150Z"
    },
    "id": "57CcilYSG0zv"
   },
   "outputs": [],
   "source": [
    "# Retrieve dataset\n",
    "dataset_url = \"https://github.com/seub/Cheezam/raw/main/data/cheese_photos_easy.tar.gz\"\n",
    "data_dir = tf.keras.utils.get_file('cheese_photos_easy', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "print(f'The data_dir is: {data_dir}')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg'))) + len(list(data_dir.glob('*/*.jpeg')))\n",
    "print(f'Found {image_count} jpg and jpeg images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyDNn9MbIzfT"
   },
   "source": [
    "## Create a tf.keras dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:26.428100Z",
     "iopub.status.busy": "2021-10-26T01:28:26.427514Z",
     "iopub.status.idle": "2021-10-26T01:28:26.429126Z",
     "shell.execute_reply": "2021-10-26T01:28:26.429494Z"
    },
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.1,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.1,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Dr0at41KcAU"
   },
   "source": [
    "## Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:29.157314Z",
     "iopub.status.busy": "2021-10-26T01:28:29.156653Z",
     "iopub.status.idle": "2021-10-26T01:28:29.160541Z",
     "shell.execute_reply": "2021-10-26T01:28:29.160912Z"
    },
    "id": "nOjJSm7DKoZA"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcUTyDOPKucd"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:42.522271Z",
     "iopub.status.busy": "2021-10-26T01:28:42.521677Z",
     "iopub.status.idle": "2021-10-26T01:28:42.637270Z",
     "shell.execute_reply": "2021-10-26T01:28:42.637709Z"
    },
    "id": "9J80BAbIMs21"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomRotation(0.1, fill_mode='constant', input_shape=input_shape),\n",
    "    layers.RandomZoom(0.1, fill_mode='constant'),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1, fill_mode='constant')\n",
    "    #layers.RandomFlip(\"horizontal\")\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    img = images[i]\n",
    "    img_aug = data_augmentation(np.expand_dims(img, axis=0))[0]\n",
    "    plt.imshow(img_aug.numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MobileV2 model from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}\n",
    "#print(model_dictionary.keys())\n",
    "model_func = model_dictionary['MobileNetV2']\n",
    "base_model = model_func(include_top=False, pooling='avg', input_shape=input_shape, weights = 'imagenet')\n",
    "base_model.trainable = False\n",
    "print(f\"Pre-trained MobileV2 model imported from Keras.\")\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes))\n",
    "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "print(f\"Added two dense layers to model.\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.time_begin = time.perf_counter()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        self.time_end = time.perf_counter()\n",
    "        self.times.append(self.time_end - self.time_begin)\n",
    "        self.time_begin = self.time_end\n",
    "    def on_train_end(self,logs = {}):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Time')\n",
    "        xticks = range(1, 1+len(self.times))\n",
    "        plt.xticks(xticks)\n",
    "        plt.plot(xticks, self.times)\n",
    "        plt.ylim(bottom=0)\n",
    "        plt.savefig('epochs_time.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:43.216138Z",
     "iopub.status.busy": "2021-10-26T01:28:43.215542Z",
     "iopub.status.idle": "2021-10-26T01:28:43.359819Z",
     "shell.execute_reply": "2021-10-26T01:28:43.360228Z"
    },
    "id": "2Zeg8zsqXCsm"
   },
   "outputs": [],
   "source": [
    "def update_history(reset, history, model_path, epochs):\n",
    "  model_path.mkdir(parents=False, exist_ok=True)\n",
    "  history_path = model_path / 'training_history'\n",
    "  if reset or (not history_path.is_file()):\n",
    "    training_history = {'acc':[], 'val_acc':[], 'loss':[], 'val_loss':[], 'epochs':0}\n",
    "  else:\n",
    "    training_history = pickle.load(open(history_path, 'rb'))\n",
    "  training_history['acc'] += history.history['accuracy']\n",
    "  training_history['val_acc'] += history.history['val_accuracy']\n",
    "  training_history['loss'] += history.history['loss']\n",
    "  training_history['val_loss'] += history.history['val_loss']\n",
    "  training_history['epochs'] += epochs\n",
    "  with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(training_history, file_pi)\n",
    "  return training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:43.383520Z",
     "iopub.status.busy": "2021-10-26T01:28:43.382812Z",
     "iopub.status.idle": "2021-10-26T01:28:59.551231Z",
     "shell.execute_reply": "2021-10-26T01:28:59.551643Z"
    },
    "id": "LWS-vvNaZDag"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "model_path = pathlib.Path.home() / '.keras/models/MobileV2'\n",
    "reset = True\n",
    "if reset==False:\n",
    "  assert model_path.is_dir()\n",
    "\n",
    "timetaken = timecallback()\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[timetaken])\n",
    "training_history = update_history(reset=reset, history=history, model_path=model_path, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 3s 633ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.6237\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 3s 691ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 1.4061 - val_accuracy: 0.6075\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 3s 702ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.6398\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "epochs = 3\n",
    "reset = False\n",
    "if reset==False:\n",
    "  assert model_path.is_dir()\n",
    "\n",
    "timetaken = timecallback()\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[timetaken], steps_per_epoch=5)\n",
    "training_history = update_history(reset=reset, history=history, model_path=model_path, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkdl8VsBbZOu"
   },
   "source": [
    "## Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:59.594843Z",
     "iopub.status.busy": "2021-10-26T01:28:59.572099Z",
     "iopub.status.idle": "2021-10-26T01:28:59.808391Z",
     "shell.execute_reply": "2021-10-26T01:28:59.808800Z"
    },
    "id": "dduoLfKsZVIA"
   },
   "outputs": [],
   "source": [
    "def visualize_training(training_history):\n",
    "    epochs_range = range(1, 1+training_history['epochs'])\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, training_history['acc'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, training_history['val_acc'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, training_history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, training_history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.savefig('output/training_history.png')\n",
    "    plt.show()\n",
    "visualize_training(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtv5VbaVb-3W"
   },
   "source": [
    "## Predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def cheezam(filepath : str):\n",
    "    img = tf.keras.utils.load_img(filepath, target_size=(img_height, img_width))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    display( PIL.Image.open(filepath).resize((img_height, img_width)) )\n",
    "\n",
    "    print(\n",
    "    \"This cheese is most likely a {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-26T01:28:59.815147Z",
     "iopub.status.busy": "2021-10-26T01:28:59.814502Z",
     "iopub.status.idle": "2021-10-26T01:29:00.126068Z",
     "shell.execute_reply": "2021-10-26T01:29:00.126427Z"
    },
    "id": "dC40sRITBSsQ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import PIL\n",
    "test_dir = pathlib.Path('data/sample_dataset')\n",
    "test_paths_total = list(test_dir.glob('*/*.jpg'))\n",
    "nb_test, nb_test_total = 10, len(test_paths_total)\n",
    "test_paths = random.sample(test_paths_total, nb_test)\n",
    "print(len(test_paths))\n",
    "for test_path in test_paths:\n",
    "    cheezam(test_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "toc_visible": true
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
